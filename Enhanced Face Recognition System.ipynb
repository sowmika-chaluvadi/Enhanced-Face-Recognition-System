{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#installation of required packages\n!pip install dlib\n!pip install face-recognition\n!pip install imutils","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:18:30.603198Z","iopub.execute_input":"2022-02-04T16:18:30.603756Z","iopub.status.idle":"2022-02-04T16:19:20.286879Z","shell.execute_reply.started":"2022-02-04T16:18:30.603645Z","shell.execute_reply":"2022-02-04T16:19:20.285938Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#blur detection\nimport cv2\nimport numpy as np\nimport glob\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport face_recognition\nfolders = glob.glob('../input/hulk-frames/Bruce Banner- Hulk')\nimagenames_list = []\nfor folder in folders:\n    for f in glob.glob(folder+'/*.png'):\n        imagenames_list.append(f)\nlaplacian_values=[]\ngrayimages_names= []        \nfor image in imagenames_list:\n    grayimages_names.append(cv2.imread(image, cv2.IMREAD_GRAYSCALE))\nfor i in grayimages_names:\n x= cv2.Laplacian(i, cv2.CV_64F).var()\n laplacian_values.append(x)\na=sorted(laplacian_values) \nhighest_five_laplacian_values=[]\n#print(highest_five_laplacian_values)\nfor i in range(-1,-6,-1):\n    highest_five_laplacian_values.append(laplacian_values.index(a[i]))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-04T16:19:20.290625Z","iopub.execute_input":"2022-02-04T16:19:20.290923Z","iopub.status.idle":"2022-02-04T16:19:23.897391Z","shell.execute_reply.started":"2022-02-04T16:19:20.290883Z","shell.execute_reply":"2022-02-04T16:19:23.896628Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#applying histogram equalization\nfig = plt.figure(figsize=(20, 20))\nrows=5\ncolumns=2\nj=0\nmatrix_array=[]\nfor i in range(0,5):\n    path=cv2.imread(imagenames_list[i],cv2.IMREAD_GRAYSCALE)\n    equ=cv2.equalizeHist(path)\n    matrix_array.append(equ)\n    fig.add_subplot(rows, columns, j+1)\n    plt.imshow(path,cmap='gray')\n    plt.axis('off')\n    plt.title(\"Before Applying Histogram Equalization\")\n    fig.add_subplot(rows, columns, j+2)\n    plt.imshow(equ,cmap='gray')\n    plt.axis('off')\n    plt.title(\"After Applying Histogram Equalization\")\n    j=j+2","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:19:23.898736Z","iopub.execute_input":"2022-02-04T16:19:23.898969Z","iopub.status.idle":"2022-02-04T16:19:25.079528Z","shell.execute_reply.started":"2022-02-04T16:19:23.898937Z","shell.execute_reply":"2022-02-04T16:19:25.077133Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#images extraction after applying histogram equalization\nnames=['One','Two','Three','Four','Five']\nimages=[]\nfor i in range(0,5):\n    data=matrix_array[i]\n    array=np.array(data,dtype=np.uint8)\n    my_image=Image.fromarray(array)\n    my_image.save(names[i]+'.png')\n    p=cv2.imread(names[i]+'.png')\n    images.append(names[i]+'.png')\n    figu = plt.figure(figsize=(5, 5))\n    rows=1\n    columns=1\n    figu.add_subplot(rows,columns,1)\n    plt.imshow(p)\n    plt.xticks([]), plt.yticks([])\n#print(images)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:19:25.081135Z","iopub.execute_input":"2022-02-04T16:19:25.081350Z","iopub.status.idle":"2022-02-04T16:19:25.823243Z","shell.execute_reply.started":"2022-02-04T16:19:25.081320Z","shell.execute_reply":"2022-02-04T16:19:25.822586Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#face detection\noriginal_image=cv2.imread('./Four.png')\ngrayscale_image = cv2.cvtColor(original_image,cv2.COLOR_BGR2GRAY)\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\nfaces=face_cascade.detectMultiScale(grayscale_image,\n                                         scaleFactor=1.1,\n                                         minNeighbors=5,\n                                         minSize=(60, 60),\n                                         flags=cv2.CASCADE_SCALE_IMAGE)\nfor (column, row, width, height) in faces:\n    cv2.rectangle(\n        original_image,\n        (column, row),\n        (column + width, row + height),\n        (0, 255, 0),\n        5\n    )\nprint(faces)\ndata=original_image\narray=np.array(data,dtype=np.uint8)\nmy_image=Image.fromarray(array)\nmy_image.save('Face_Detection'+'.png')\np=cv2.imread('Face_Detection'+'.png')\nimg = cv2.imread('./Face_Detection.png')\nplt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\nplt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\nplt.show()\nprint(images)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:19:25.824554Z","iopub.execute_input":"2022-02-04T16:19:25.824952Z","iopub.status.idle":"2022-02-04T16:19:26.394976Z","shell.execute_reply.started":"2022-02-04T16:19:25.824916Z","shell.execute_reply":"2022-02-04T16:19:26.392082Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#face detection\nfor i in images:\n    imgelon =face_recognition.load_image_file(i)\n    #print(imgelon)\n    imgelon_rgb= cv2.cvtColor(imgelon,cv2.COLOR_BGR2RGB)\n    #print(imgelon_rgb[0])\n    #----------Finding face Location for drawing bounding boxes-------\n    face = face_recognition.face_locations(imgelon_rgb)[0]\n    copy = imgelon.copy()\n    #-------------------Drawing the Rectangle-------------------------\n    print(face)\n    cv2.rectangle(copy, (face[3], face[0]),(face[1], face[2]), (255,0,255), 5)\n    figu = plt.figure(figsize=(5,5))\n    rows=1\n    columns=1\n    figu.add_subplot(rows,columns,1)\n    #plt.imshow(p)\n    plt.xticks([]), plt.yticks([])\n    plt.imshow(copy)\n    plt.xticks([]), plt.yticks([])\n    #plt.imshow(imgelon)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:19:26.396529Z","iopub.execute_input":"2022-02-04T16:19:26.396809Z","iopub.status.idle":"2022-02-04T16:19:27.645916Z","shell.execute_reply.started":"2022-02-04T16:19:26.396772Z","shell.execute_reply":"2022-02-04T16:19:27.645125Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#model training\nfrom imutils import paths\nimport face_recognition\nimport pickle\nimport cv2\nimport os\n \n#get paths of each file in folder named Images\n#Images here contains my data(folders of various persons)\nimagePaths = list(paths.list_images('../input/trainingdata1/Avengers/cropped_images'))\nknownEncodings = []\nknownNames = []\nname=''\n# loop over the image paths\n#print(imagePaths)\nfor (i, imagePath) in enumerate(imagePaths):\n    # extract the person name from the image path\n    if imagePath.split(os.path.sep)[-1][0:8]=='scarlet':\n        name='BlackWidow'\n    elif imagePath.split(os.path.sep)[-1][0:5]=='chris':\n        name='CaptainAmerica'\n    elif imagePath.split(os.path.sep)[-1][0:4]=='mark':\n        name='Hulk'\n    elif imagePath.split(os.path.sep)[-1][0:6]=='robert':\n        name='IronMan'\n    elif imagePath.split(os.path.sep)[-1][0:5]=='chris':\n        name='Thor'\n    #print(name)\n    # load the input image and convert it from BGR (OpenCV ordering)\n    # to dlib ordering (RGB)\n    image = cv2.imread(imagePath)\n    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    #Use Face_recognition to locate faces\n    boxes = face_recognition.face_locations(rgb,model='hog')\n    # compute the facial embedding for the face\n    encodings = face_recognition.face_encodings(rgb, boxes)\n    # loop over the encodings\n    for encoding in encodings:\n        knownEncodings.append(encoding)\n        knownNames.append(name)\n#save emcodings along with their names in dictionary data\ndata = {\"encodings\": knownEncodings, \"names\": knownNames}\n#use pickle to save data into a file for later use\nf = open(\"face_enc\", \"wb\")\nf.write(pickle.dumps(data))\nf.close()\n#print(data)","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:19:27.650469Z","iopub.execute_input":"2022-02-04T16:19:27.650761Z","iopub.status.idle":"2022-02-04T16:20:01.901465Z","shell.execute_reply.started":"2022-02-04T16:19:27.650705Z","shell.execute_reply":"2022-02-04T16:20:01.900680Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"names=[]\nfor i in images:\n    image=cv2.imread(i)\n    rgb=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    encodings = face_recognition.face_encodings(rgb)\n    # loop over the facial embeddings incase\n    # we have multiple embeddings for multiple faces\n    for encoding in encodings:\n        #Compare encodings with encodings in data[\"encodings\"]\n        #Matches contain array with boolean values and True for the embeddings it matches closely\n        #and False for rest\n        matches = face_recognition.compare_faces(data[\"encodings\"],encoding)\n        #set name =inknown if no encoding matches\n        #name = \"Unknown\"\n        # check to see if we have found a match\n        unknown=[\"Unknown\"]\n        if True in matches:\n            #Find positions at which we get True and store them\n            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n            counts = {}\n            # loop over the matched indexes and maintain a count for\n            # each recognized face\n            for i in matchedIdxs:\n                #Check the names at respective indexes we stored in matchedIdxs\n                name = data[\"names\"][i]\n                #increase count for the name we got\n                counts[name] = counts.get(name, 0) + 1\n                #set name which has highest count\n                name = max(counts, key=counts.get)\n                #print(name)\n \n            # update the list of names\n                names.append(name)\n                #print(names)\n                #print(face)\n            # loop over the recognized faces\n            for((x,y,w,h),name) in zip(faces,names):\n                # rescale the face coordinates\n                # draw the predicted face name on the image\n                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0),2)\n                cv2.putText(image,name, (x,y), cv2.FONT_HERSHEY_SIMPLEX,\n                 1, (0, 255, 0),3)\n        else:\n            names.append(\"Unknown\")\n            # loop over the recognized faces\n            for ((x, y, w, h), name) in zip(faces,unknown):\n                # rescale the face coordinates\n                # draw the predicted face name on the image\n                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0),2)\n                cv2.putText(image, name, (x,y), cv2.FONT_HERSHEY_SIMPLEX,\n                 1, (0, 255, 0),3)\n        #print(names)\n        figu = plt.figure(figsize=(5,5))\n        rows=1\n        columns=1\n        figu.add_subplot(rows,columns,1)\n        plt.imshow(p)\n        #plt.xticks([]), plt.yticks([])\n        #plt.imshow(copy)\n        #plt.xticks([]), plt.yticks([])\n        plt.imshow(image)\n        plt.xticks([]), plt.yticks([])","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:31:37.093091Z","iopub.execute_input":"2022-02-04T16:31:37.093350Z","iopub.status.idle":"2022-02-04T16:31:38.866910Z","shell.execute_reply.started":"2022-02-04T16:31:37.093322Z","shell.execute_reply":"2022-02-04T16:31:38.866253Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def names_count(images_list):\n    counts = dict()\n    for image in images_list:\n        if image in counts:\n            counts[image] += 1\n        else:\n            counts[image] = 1\n    counts_x = sorted(counts.items(), key=lambda kv: kv[1])\n    #print(counts_x)\n    return counts_x\nprint(len(images))\n#print(names)\nhighest=names_count(images)\n#print(highest)\n#print(highest[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:29:57.080646Z","iopub.execute_input":"2022-02-04T16:29:57.080923Z","iopub.status.idle":"2022-02-04T16:29:57.087184Z","shell.execute_reply.started":"2022-02-04T16:29:57.080892Z","shell.execute_reply":"2022-02-04T16:29:57.086351Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"Avenger_Names=['CaptainAmerica','IronMan','Hulk','Thor','BlackWidow']\nif highest[0] in Avenger_Names:\n    print('Is an Avenger')\nelse:\n    print('Is Not an Avenger')","metadata":{"execution":{"iopub.status.busy":"2022-02-04T16:20:03.624374Z","iopub.execute_input":"2022-02-04T16:20:03.624818Z","iopub.status.idle":"2022-02-04T16:20:03.631933Z","shell.execute_reply.started":"2022-02-04T16:20:03.624779Z","shell.execute_reply":"2022-02-04T16:20:03.630591Z"},"trusted":true},"execution_count":10,"outputs":[]}]}